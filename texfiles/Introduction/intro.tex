\chapter[Introduction]{Introduction}
A complex network is a graph-based representation of the interactions amongst entities that take place in the real world. Examples include
social
networks such as acquaintance networks~\cite{Amaral},
collaboration networks~\cite{newman_01}, technological networks such as the
Internet~\cite{Faloutsos:1999} and the World Wide Web~\cite{albert1999internet}, and biological networks such as neural
networks~\cite{Watts-1998}, and metabolic networks~\cite{Jeong}. Real networks are
not random and they usually exhibit {\em inhomogeneity}~\cite{Barabasi99}, indicating the coexistence of order and organization.
Furthermore, the
distribution of links also shows inhomogeneity, both globally and locally, describing the phenomenon that
nodes naturally cluster into groups and links are more likely to connect nodes within the same group. This phenomenon tells us that the
organization of such complex network is modular. Network scientists call this organization as the {\it community structure} of networks. Though
there is a lack
of consensus in the definition of communities, most popular and well-accepted definition suggests that: communities are the subsets of
vertices within which vertex-vertex connections are dense, but between which connections are less dense~\cite{Girvan02}. A figurative
sketch and a real-world community structure are shown in Figure~\ref{demo}. Analysis of such communities is essential to understand the
structural and the functional organizations of the network.   

\if{0}
Mobile devices are becoming truly ubiquitous. The {\em World Health Organization} estimates that more than $700$ million people do not have access to clean drinking water and over $2.5$ billion do not have access to toilets. However, according to the {\em International Telecommunications Union}, $96\%$ percent of the world is connected via cellphone\footnote{http://www.nytimes.com/2013/11/08/giving/ubiquitous-across-globe-cellphones-have-become-tool-for-doing-good.html?\_r=0}. A significant amount of these devices are smart. Popularity of smart devices can be realized from the sale statistics of Smartphones. A statistics on Smartphone sale released by {\em Statista}~\cite{mobile_sell_stat_statistica} shows the year wise Smartphone sale from year $2007$ to year $2013$.  Fig.~\ref{mobile_sell} shows an exponential growth of sale after the year $2009$. This trend will continue in near future which is clear from another survey which predicts that by $2017$, sale of $87\%$ of connected devices will be either 
Smartphone or Tablet\footnote{http://www.forbes.com/sites/louiscolumbus/2013/09/12/idc-87-of-connected-devices-by-2017-will-be-tablets-and-smartphones/}. 
\begin{figure}[h!t]
\begin{center}
\includegraphics[width=3.4in, height =2.3in]{./figs/Introduction/mobile_sell.pdf}
\caption{World wide mobile sale per year in million unit (reproduced from~\cite{mobile_sell_stat_statistica})}
\label{mobile_sell}
\end{center}
\end{figure}
\fi

\section{Major Challenges}
Detecting communities is of prime importance in sociology, biology and computer science disciplines where systems are often represented as
graphs. This problem is very hard and not yet satisfactorily solved, despite the huge effort of a large interdisciplinary community of
scientists working on it over the past one and half decades (see~\cite{Fortunato201075} for the reviews). Besides this,
several other challenges have been encountered during the analysis of community structure in large networks, some of which are as follows:
\if{0}
Furthermore, the contribution of traffic from smart devices is clearly dominating the negligible amount of traffic from non-smart devices~\cite{mobile_stat_cisco_2013} (see Fig.~\ref{mobile_smart}).
\begin{figure}[h!t]
\begin{center}
\includegraphics[width=3.4in, height =2.3in]{./figs/Introduction/data_demand_from_smart_and_not_smart_device.pdf}
\caption{Data traffic from smart and not-smart devices (reproduced from~\cite{mobile_stat_cisco_2013})}
\label{mobile_smart}
\end{center}
\end{figure}
\fi
\begin{itemize}

\item  The goodness of community detection algorithms (see~\cite{Fortunato:2009} for a review) is often objectively measured according to
how well they achieve the optimization. Modularity~\cite{ng2002} is a widely accepted metric for measuring the quality of community
structure identified by various community detection algorithms. However, a growing body of research have begun to explore the limitations of
maximizing modularity for community identification and evaluation; three such limitations include -- resolution limit \cite{gmc2010},
degeneracy of solutions and asymptotic growth of the modularity value.
Therefore, a new goodness measurement metric needs to be formulated that can overcome (or minimize) such limitations.
 
\item Due to the limitations of the goodness measures (such as modularity) described above, researchers often rely on manual inspection in
order
to evaluate the detected communities. For each detected community an
effort is made to interpret it as a ``real'' community by identifying a common property or external attribute shared by all the members of
the community. Such anecdotal evaluation procedures require extensive manual effort; therefore these are non-comprehensive and are limited
to small networks.
Therefore, a possible solution would be to find a reliable definition of explicitly labeled ground-truth communities.

\item Although there is a large volume of research on community detection, systematic post-hoc analysis of the communities, which can
unfold interesting characteristic properties of various real systems, is missing in the literature. For instance, temporal community
interactions on a longitudinal scale (i.e, with the progress of time)  often unveil the opportunity to analyze the rise and fall of
dominant clusters in
different time points. This analysis might be helpful in detecting the trending topics in Twitter, identifying major research
fields in different scientific domains, information diffusion among scientific communities~\cite{Shi} etc.     
\end{itemize}

Given this scenario, it is clear that we need to develop a better understanding of community structure in various types of large networks.
The goal of our research is to study different aspects of community analysis in complex networks that mainly focus on two major directions
-- (i) identification of realistic communities in different large networks and (ii) leveraging such community structure for developing
various
applications. 


\section{Objectives}

To deal with all the challenges mentioned above, we identify four major issues mentioned below that contribute to different chapters
of the thesis. 

{\bf (i) Investigating the dependence of community detection algorithms on vertex ordering:} Here we intend to study the variation of
results produced by the algorithms due to different vertex
orderings. Moreover, we posit that despite any vertex ordering, there exist some invariant
groups in each network whose constituent vertices always remain together. In particular, we
ask the following questions -- what does the invariance of the results tell us about the network
structure? what is the significance of these invariant substructures in a network? how are they
related with the actual community structure of a network?


{\bf (ii) Formulating a new metric for community analysis:}
Most of the community scoring functions are global, thus do not imply anything about the vertices of a network. We believe that the
individual constituent vertices in a community do not belong to the community with equal strength. Further, there is a lack of a proper
quantitative indicator that would entail the true
modular structure of a network. For instance, the highest modularity in the Jazz network is
0.45 and that of the Western  USA  power grid is 0.98~\cite{Newman:2006}. However, it has been observed 
 that Jazz has a much stronger community structure than the power grid \cite{Newman:2006}. Therefore, formulation of a vertex-centric
measure for
community analysis that correctly indicates the presence of community structure in a network is needed.

Here we intend to ask few fundamental questions pertaining to the community analysis of a network -- is the membership of vertices in a
community homogeneous (which has been the common consensus so far)? do we need to check the eligibility of a network for community
detection prior to running the community detection algorithm? can one formulate a metric  that suitably reduces the limitations of
the existing metrics for community detection?


{\bf (iii) Analyzing real-world community structure:}
Several works on detecting and tracking communities in a temporal environment have been conducted~\cite{Fortunato:2009}. However, the
interactive patterns of detected communities over a temporal scale still remain unexplored mainly due to the lack of standard
ground-truth community structure of a network. The availability of ground-truth communities allows to explore a range of interesting
characteristics of a time-varying systems. For example,
deep understanding of the connectivity structure in and across ground-truth communities could lead to realistic community detection
methods. Here, we focus on a typical real network, {\em citation network}, whose nodes correspond to
scientific
articles and links correspond to the citations from citing papers to cited papers. 
We aim at investigating different aspects of this network such as -- how do the communities form in this network? what do the topological
features of citation network tell us? what can we learn from them?  what kind of trends are observed over-time in these
networks? how often
do authors publish and collaborate? 

{\bf (iv) Developing community based applications:} 
Once the community structure is detected from a network, an immediate question might arise that how this information can help us in building
real applications. Citation profiles over time can be shown to group in different communities, which can be further used to develop more
accurate citation prediction models. Further, it is possible to arrange citations into semantic communities which can facilitate developing
a full-fledged faceted recommendation system of scientific articles.


\section{Constant Communities in Networks}
An automatic way of detecting the communities from networks has attracted much attention in recent years and many community detection
algorithms have been proposed. Most of these algorithms are based on the maximization of a quality function known as modularity,
which measures difference between the fraction of edges in the network that connect vertices of the same type (within community type) and
the expected value of the same quantity in a network with the similar community divisions but random connection between vertices
 (see Section \ref{nonover_comm}). Modularity maximization is an NP-hard problem \cite{Brandes}, and most algorithms use heuristics.
For several reasons related to the modularity, as well as the non-determinism of the algorithms or randomness in initial configuration, such
algorithms often produce different partitions of similar quality, and there is no reason to prefer one above another. Besides, such
approaches
may produce communities with a high modularity in networks which have no community structure, e.g., random networks. This is related to the
instability of algorithms: small perturbations of the input graph can significantly influence the output.

Here, we investigate the effect of input ordering on two non-deterministic agglomerative methods for modularity maximization -- (i) CNM
algorithm \cite{cnm2004} and (ii) Louvain method \cite{bgll2008}. Both these methods are based on combining appropriate pairs of vertices to
increase modularity. Based on these results, we posit that the permutation of the vertices is a key point for obtaining high modularity. A
bad
permutation can lead to sub-optimal combination of vertex pairs that in turn can affect the communities obtained. The notion of stability is
governed by the inherent compartmental structure of the nodes in a network. Our intuition is based on the fact that some vertices always
persist within same communities despite any combinatorial ordering of input edge sequence. Those vertices may have some intrinsic
connectivity property that forces them not to share other communities under any circumstance. We call such groups of vertices as {\em
constant communities} and the constituent vertices as {\em constant vertices}. We observe that if these constant vertices are grouped
together in the pre-processing step, it significantly improves the accuracy of hierarchical clustering technique by increasing the
modularity. We further analyze the properties of constant communities in order to identify the characteristic that keep them together
independent of the order of the vertices in which the community detection algorithm is fed in. In particular, we observe that
constant vertices experience minimum ``pull'' from external nodes in the network. Further, we present a case study on phoneme network and
illustrate that constant communities, quite strikingly, form the core functional units of the larger communities.

\section{Permanence and Network Communities}
Community detection algorithms primarily deal with identifying densely-connected units from within large networks. So far, the common
consensus in the analysis of the community structure  is that the community membership is homogeneous, i.e., each node belongs to one or
more communities with equal extent. Therefore, less attention has been paid in analyzing individual vertices in a community, and a community
is mostly considered as a whole. Here we argue that the community membership of vertices is {\em heterogeneous}; where few vertices have
more involvement into the community and others have less. To quantify the membership of a vertex, we need a proper local vertex-based
metric. 
Modularity is a widely  accepted global metric for measuring the quality of community structure identified by various community detection
algorithms. However, a growing body of research have begun to explore the limitations of maximizing modularity for community identification
and evaluation; three such limitations include -- resolution limit \cite{Fortunato:2007}, degeneracy of solutions \cite{gmc2010} and
asymptotic growth of the modularity value \cite{gmc2010}. 

To address these issues, we here propose a novel vertex-level metric called {\em permanence} (Perm) for analyzing disjoint communities which
is built on the 
notion of relative pull experienced by a vertex from its neighbors that lie external to its own community. The value of permanence
indicates the extent to which a vertex belongs to a community. We show that this metric as
compared to
other standard measures, namely modularity, conductance and cut-ratio qualifies as a better community scoring function for evaluating the
detected community structures from both synthetic and real-world networks. We demonstrate that the process of maximizing permanence produces
communities that concur with the ground-truth structure of the networks more accurately than the modularity based and other approaches.
Finally, we show that maximizing permanence (named as MaxPerm) can effectively reduce the limitations associated with modularity
maximization as well as can indirectly help in inferring the community quality of a network.

Further, we formulate a generalized version of this metric called {\em overlapping permanence} (abbreviated as OPerm) that, although is
developed for overlapping community, translates to the non-overlapping case under special boundary conditions. Note that this is one of
the rarest formulations which can be useful for both non-overlapping and overlapping community analysis. Since every
vertex gets scored by this metric, it can be used to rank the vertices within a community as well as can give an overview of the
belongingness of nodes in the community. Detailed experimentation demonstrates OPerm's superiority over other state-of-the-art scoring
metrics in terms of performance as well as its resilience to minor perturbations. We also present an algorithm, MaxOPerm, to detect
communities
based on maximizing OPerm. Over a test suite of synthetic and six large real-world networks we show that MaxOPerm outperforms six
state-of-the-art algorithms in terms of accurately predicting the ground-truth labels. We also demonstrate that MaxOPerm is resistant to
degeneracy of solution. Further, we introduce the resolution limit problem in the context of overlapping communities and show that an
algorithm which can maximize OPerm can effectively tackle the problem.



\section{Analyzing Ground-truth Communities}
Most of the existing works on community analysis have concentrated on developing and improving the algorithms for discovering communities.
Evaluating the performance of such algorithms is incomplete without comparing the detected output with the actual ground-truth community
structure of the network under investigation. However, such ground-truth community structure is limited in number. 
Moreover, availability of such community structure of a labeled network  would unveil the opportunity to investigate its 
characteristics and functionality thoroughly. To this purpose, we particularly focus on a scientific network, called {\em
citation network}, whose nodes indicate scientific articles and links correspond to the citations. We gather all the papers in computer
science domain published in the last fifty years and indexed by Microsoft Academic
Search\footnote{\url{http://academic.research.microsoft.com/}}.
Each paper comes along with various bibliographic information -- the title of the paper, a unique index number, its author(s) etc.
Each individual community in a citation network is naturally defined by a research field -- i.e., acting as ground-truth. Then we study
the interactions among these communities through citations in real time which unfold the landscape of dynamic research trends in the
computer science domain over the last fifty years. We quantify the interaction in terms of a metric called {\em inwardness} that
captures the effect of local citations to express the degree of {\em authoritativeness} of a community (research field) at a particular time
instance. Several arguments to unfold the reasons behind the temporal changes of inwardness of different communities are put forward using
exhaustive statistical analysis. The measurements (importance of field) are compared with the project funding statistics of
NSF and it is found that the two agree to a considerable extent.

As a second step we quantify the interdisciplinarity of a research field through four indicative
measures. Three of the indicators, namely {\em Reference Diversity Index} ({\em RDI}), {\em Citation Diversity Index} ({\em CDI}) and
{\em Membership Diversity Index} ({\em MDI}) are directly related to the topological structure of the citation network. The last feature
called the {\em Attraction Index} of a field is based on the propensity of the new researchers to start research in a particular field.
Further, to check the significance of these features in characterizing interdisciplinarity, we rank the fields based on the value of each of
the features separately. Next, we propose an unsupervised classification model  that can efficiently cluster the core and the
interdisciplinary fields based on the similarity of the feature sets mentioned above. To understand the evolutionary
landscape of a core field vis-a-vis an interdisciplinary field, we conduct a case study on one popularly accepted interdisciplinary field
(WWW) and one core
field (Programming Languages). The results attest to
the conclusion that the interdisciplinarity occurs through cross-fertilization of ideas between the fields that otherwise have little
overlap as they are studied independently.  The conclusion that popularity of the interdisciplinary research now-a-days overshadows the
core fields is strengthened on analyzing the core-periphery organization of the citation network at different time periods. We observe that
the core region of a domain is gradually dominated by the more applied fields with interdisciplinary fields steadily accelerating towards
the core. 

The rich citation dataset further allows us to conduct an author-centric analysis. In particular, we analyze the diverse scientific careers
of researchers in order to understand the key factors that could lead to a successful career. Essentially, we intend to answer some specific
questions pertaining to a researcher's scientific career -- what are the local and the global dynamics regulating a researcher's decision to
select a new field of research at different points of her entire career? what are the suitable quantitative indicators to measure the
diversity of a researcher's scientific career? We propose two entropy-based metrics to measure a researcher's choice of research topics.
Experiments with large computer science bibliographic dataset reveal that there is a strong correlation between the diversity of the career
of a researcher and her success in scientific research in terms of the number of citations. We observe that while most of the researchers
are biased toward either adopting diverse research fields or concentrating on very few fields, a majority of the highly cited researchers
tend
to follow a typical ``scatter-gather'' policy -- although their entire careers are immensely diverse with different types of fields
selected at different time periods, they remain focused primarily in at most one or two fields at any particular time point of their career.
 

\section{Community-based Applications}
The group of homogeneous entities can be useful in several applications. Here we particularly focus on two major applications that are
built on the citation networks and publication datasets. Prior to that, we study another important aspect of a scientific article, its
growth of citation counts over time after the publication. A common consensus in the literature is that the citation profile of published
articles in general follows a universal pattern -- an initial growth in the number of citations within the first two to three years after
publication followed by a steady peak of one to two years and then a final decline over the rest of the lifetime of the article. This
observation has long been the underlying heuristic in determining major bibliometric factors such as the quality of a publication, the
growth of scientific communities, impact factor of publication venues etc. We study the citation network once again and notice that the
citation count of the articles over the years follows a remarkably diverse set of patterns -- a profile with an initial peak (PeakInit),
with distinct multiple peaks (PeakMul), that exhibits a peak late in time (PeakLate), that is monotonically decreasing (MonDec), that is
monotonically increasing (MonIncr) and that cannot be categorized into any of the above (Oth)). The papers following same citation profile
are assumed to form separate community. We systematically investigate the important
characteristics of each of these categories. 

Then we leverage this category information in order to develop a prediction model that predicts future citation count of a scientific
article after a
given time interval of its publication.  We propose to categorize the complete set of data samples into different subparts each of which
corresponds to one type of citation pattern mentioned earlier. This approach is commonly termed as {\em stratified learning} in the
literature
where the members of the stratified space are divided into homogeneous subgroups (aka strata) before sampling. We develop a {\em two-stage
prediction model} -- in the first stage, a query paper is mapped into one of the strata using a
Support Vector Machine (SVM) approach that learns from a bunch of features related to the author, the venue of the publication and the
content
of the paper; in the second stage, only those papers corresponding to the strata of the query paper are used to train a Support Vector
Regression (SVR) module to predict the future citation count of the query paper. For the same set of features available at the time of
publication, the two-stage prediction model remarkably outperforms (to the extent of 50\% overall improvement) the well-known baseline
model. Our two-stage prediction model produces significantly better accuracy in predicting the future citation count of the highly-cited
papers that might serve as an useful tool in early prediction of the seminal papers that are going to be popular in the near future. 
We also show that including the first few years of citations of the paper into the feature set can significantly improve 
the prediction accuracy especially in the long term. 

Finally, we arrange citations into semantic communities based on the relation of a cited paper with the citing paper. We use this grouping
to propose for the first time a framework of faceted recommendation for scientific articles, {\em FeRoSA} which apart from ensuring
quality retrieval of scientific articles for a particular query paper, also efficiently arranges the recommended papers into different
facets (categories).  Our methodology is based on a principled framework of random walks where both the citation links and the content
information are systematically taken into account in recommending the relevant results. First, citation links are categorized into four
classes/facets, namely Background, Alternative Approaches, Methods and Comparison. Following this, for a particular query paper, we collect
an initial pool of papers containing nearest citation-based neighborhoods and papers having high content-similarity with the query paper,
and make an induced graph individually for each facet. Next, a random walk with restarts is performed from the query paper on each of the
induced subgraphs and a  ranked list of papers is obtained. We further prepare another ranked list of papers based on the content
similarity. The final ranking is obtained in a principled way by combining multiple ranked lists.  Our method is easy to implement and has
very elegant and principled way of retrieving the relevant results irrespective of the choice of the facets. Human experts are asked to
judge the recommendations of the competing systems. Experimental results show that our system outperforms the baseline systems with respect
to different standard measures which are used to evaluate a recommendation system. In terms of overall precision, FeRoSA achieves an
improvement of 29.5\% compared to the best competing system. We also evaluate and compare the results separately for different facets
(average
overall precision of 0.65) and model parameters to have a thorough understanding of the
performance of the system.


\section{Contributions}
In this thesis, we consider {\em community analysis in complex network} as a prime objective, which has been one of the active research
topic  for quite some time in different branches of science including computer science, physics, mathematics and
biology. Despite a large
volume of research in this area, few fundamental problems have remained unanswered or have not been solved satisfactorily.
Here we attempt to analyze such problems. Moreover, we focus on {\em citation
network} and study different structural and functional aspects of this network. Finally, we design two applications based on the
publication dataset which leverage the community information of the underlying network. A brief report (which we shall elaborate in
the forthcoming chapters) on these studies and the results obtained thereby, are presented below. 

\subsection{Constant Communities in Networks}
Although enormous effort has been devoted to design efficient community detection algorithms, most of these algorithms
follow a general framework -- these
algorithms try to optimize certain objective functions (such as modularity) by grouping vertices, which results in the partitioning of the
vertices in the network. However, most of these algorithms are highly dependent on the ordering in which the vertices are processed as a
result of which the algorithms produce different outputs in different iterations for a particular network. An exhaustive study of this
phenomenon reveals the following interesting results:

\begin{enumerate}[(a)]

 \item We conduct this experiment on a set of scale-free networks and observe that while the vertex orderings produce very different set of
communities, some groups of vertices are always allocated to the same community for all different orderings. We define the group of vertices
that remain invariant as {\em constant community} and the vertices that are part of the constant communities as {\em constant vertices}. 

\item Although constant communities are detected using the outputs obtained from certain community detection algorithms, we notice that
these groups are the invariant part of a network, irrespective of the heuristic being used to detect the communities.

\item Another issue that has not been studied earlier is whether a network at all contains community structure or not. For instance, a
random network or a grid network does not have strong community structure as compared to the ring of cliques. Therefore, we propose a
metric, called {\em sensitivity} (based on the number of constant communities within a network) which efficiently demonstrates how
community-like a network is. Later in Chapter 4, we use this metric to measure the {\em degeneracy of solutions} of an algorithm,
which although has been studied several times, is quantified here for the first time.   

\item Constant communities are quite different from the actual community structure of a network. For instance, constant
communities do not always have more internal connections than external connections. Rather, the strength of the community is determined by
the number of different external communities to which it is connected. Therefore, we characterize constant vertices by a metric
called {\em relative pull}, which indicates that the constant vertices do not experience a significant ``pull'' from any of the
external communities that will cause them not to migrate, and, therefore, their propensity to remain within their own communities is high. 

\item Further, we show that if these constant communities are identified prior to any community detection, and each constant community is
combined into a super-vertex, it not only increases the efficiency of any community detection algorithm, but also reduces the
variability of the final output.

\item Finally, we conduct a case study on a specific type of labeled linguistic network constructed from the speech sound inventories of the
world's languages. We discover constant communities from this network and observe that each such graph  represents a natural
class, i.e., a set of consonants that have a large overlap of the features. Such groups are frequently found to appear together across
languages. 

\end{enumerate}

 

\subsection{Permanence and Network Communities}
Motivated by  the earlier study on constant communities, we further investigate the community structure of real-world networks. Since many
real-world communities are
based on subjective measurements (as opposed to a formal definition), often the optimum value of the parameters are successful in
identifying only a fraction of the ``ground-truth'' communities. Moreover, as observed in the phenomena of resolution limit
\cite{Fortunato:2007} and degeneracy of solutions \cite{gmc2010}, the optimum parameter value sometimes produces intuitively incorrect
solutions in ideal networks. As a response to these issues, new metrics are being regularly proposed \cite{Dongxiao, Yang:2012}, that either
produce more accurate results on a certain subclass of networks and/or can address some of these inherent problems.

Despite the on-going research in this area, an important question is whether it is always reasonable to assign every individual vertex to a
community. Not all networks possess community structures of equal strength. For example, a network composed of several sparsely connected
dense cliques will have strong communities whereas a grid will not have any community structure at all, and between these two extremes there
exist communities of different strength as per the network structure. As of now, there is no community detection metric that can measure to
what extent a vertex is a part of a community. One of the reasons for this deficiency is that the optimum value of the parameters such as
modularity is not  exactly related to whether the network possesses a strong community, but rather tries to identify the best community
assignment, for any given network.  Indeed, most algorithms output a set of communities regardless of whether the network (such as a
grid) possesses a community structure or not.  A corollary to this problem is that given a suboptimal answer we cannot estimate how close we
are to the correct result and in the absence of ground-truth community structure, we cannot even judge whether the obtained answer is
reliable or not. These are serious limitations for a field that regularly encounters new applications and datasets.

To manage this huge mobile data traffic, we need to explore all the avenues that come across. We have identified three major issues from the scope discussed above related to mobile data traffic management as our objective of this thesis.
\begin{itemize}
 \item [] {\em Efficient Offload using WiFi Network:} Cellular network is becoming heavily congested. Capacity of 3G network is becoming inadequate to carry current traffic load, hence increasingly stress is given towards deployment of 4G network. About 4G network, Allen Nogee, a principal analyst at the In-Stat research firm commented that ``They're not really for speed, they're not really for voice, they're for capacity''\footnote{http://it-code-news.blogspot.in/2010/03/it-news-headlines-ars-technica-30032010.html}. A more immediate solution towards reducing congestion of overloaded cellular network is by offloading it to the Wi-Fi network. In this thesis, we work to explore the opportunity of enhancing Wi-Fi offloading performance through {\em data caching}. An interesting statistics of YouTube is that $10\%$ of contents are accessed for $80\%$ of times. That means even if we can do some special arrangement about this popular file then traffic load can reduce heavily. Hence one important objective of this thesis is to devise a distributed caching policy of popular files to enhance Wi-Fi offload performance.\\ 
 \item [] {\em Managing Heterogeneous Traffic:} From different study of human mobility models, it is known that traffic across network is not evenly distributed. Simple RSSI based association strategy will overload some access points while most of the access points remain under utilized and many users will remain unassociated. One objective of this thesis is to develop an association control protocol which can handle the uneven load distribution and accommodate maximum clients.\\
 \item [] {\em Restricting Unauthorized Traffic:} There are many paid services which grant access to valuable content like movies, news, songs etc. People used to share subscription credential of such services either under social pressure or to reduce per head subscription charge. As an effect this increases unauthorized traffic as well as loss of revenue for service providers. Hence, the final objective of this thesis is to restrict unauthorized traffic by means of restricting password sharing.
\end{itemize}


\section{Efficient Offload using WiFi Network} To accommodate the huge cellular traffic, cellular network providers are depending significantly on Wi-Fi network, so that they can offload less priority cellular data to Wi-Fi network. According to Cisco's prediction, Wi-Fi traffic will be dominating over Cellular network traffic by the end of $2018$. Fig.~\ref{mobile_data_offload} shows the prediction of offloaded traffic in Wi-Fi network.\\

\begin{enumerate}
\item We identify a precise rank order among the vertices within a community by arranging them into a core-periphery structure based on
OPerm; this rank order can be further used as an input for various other applications (e.g., initiator selections in message spreading).


\item Maximizing Perm (maximizing OPerm) is more successful in finding ground-truth communities as compared to state-of-the-art
algorithms.
\item Community detection using maximizing Perm (maximizing OPerm) can overcome the problem related to resolution limit, degeneracy of
solutions, in many
networks.
Moreover, the value of Perm (OPerm) is relatively independent of the size of the network. 

\end{enumerate}


\subsection{Analyzing Ground-truth Communities}
 Even though modeling network communities is a fundamental
problem, our understanding of networks at the level of these communities has been relatively less. Moreover, the lack of reliable
ground-truth makes the evaluation of such models extremely difficult. Here we study the connectivity structure of ground-truth communities
of a real network, citation network of computer science domain whose
nodes correspond to the scientific articles and links correspond to the citations. Our work is based on a large scale
citation
network where we can reliably define the notion of ground-truth communities. In this network, each paper (node) is marked by its relevant
research field; thus citation interactions among papers within a same research field are relatively higher than across fields. These fields
therefore act as ground-truth communities in the network. The availability of the reliable ground-truth communities has a profound effect,
such as it allows us to understand the connectivity structure of the ground-truth communities and the interaction among these communities
that has the potential to portray a significantly better picture of the underlying systems.


\begin{enumerate}[(a)]
 \item To start with, we first study the temporal interaction among communities in citation network by defining  a metric called
``authoritativeness'' which measures the impact of a community in a particular time period. These patterns of interaction, when analyzed
carefully, reveal various interesting elements that are either directly or indirectly related to the overall decline in the interest in a
field followed by the rise of interest in another. One of the most striking observations is that in almost all cases, the
field constituting the current ``hottest'' area of research within the domain is overtaken in the immediate future by its strongest
competitor.

\item We further investigate the cause of such focus shifts from different and possibly orthogonal directions and observe
that (a) the density of high impact publications within a field plays a pivotal role in pulling as well as sustaining the field at the
forefront, (b) certain fields produce a huge number of citations (i.e., act as hubs) for a particular field and, thereby, push it to the
forefront; an abrupt fall in the number of such received citations, in many cases, triggers the decline of the field currently at the
forefront, (c) inception of seminal papers in a field might trigger the emergence of a field at the forefront, and (d) the extent of
team work (both within and across continents) in the form of joint publications seem to significantly contribute to the shape of the
evolutionary landscape.



\item  A careful analysis of the funding trends by NSF (National Science Foundation of the United States
of America) shows that our results correlate very well with the number of proposals submitted in each field while they correlate moderately
well with the actual funding decisions. 

\end{enumerate}

 
A common consensus among researchers is that interdisciplinarity is one of the key factors in doing research at current times. However, a
pertinent question deals with identifying appropriate indicators of interdisciplinarity. Using a set of citation
based indicators, here we investigate the evolution of the extent of interdisciplinary research in computer science. For this, we
study the citation network from different orthogonal directions, namely citation and reference patterns of a paper, overlapping membership
of the papers in different research communities, inclination of the researchers to adopt new fields, and propose several indices to
quantify the degree of interdisciplinarity of a field. The new indices of interdisciplinarity corroborate with the hypothesis
that the emergence of interdisciplinarity occurs through cross-fertilization of ideas between the sub-fields that otherwise have
little overlap as they are studied independently. At the end, we analyze the core-periphery organization of citation networks
and arrive to the conclusion that with the advancement of interdisciplinary research, the core part of the network is also
changing from theoretical towards more applied fields of research. Some of our observations are as follows.

\begin{enumerate}[(a)]
 \item The practice of interdisciplinarity in citations occurs mainly between related scientific communities, and this phenomenon has been
witnessed to tremendously increase over the last few years.

\item Few fields such as Data Mining, WWW, Natural Language Processing, Computational Biology, Computer Vision, Computer Education provide
clear indications of interdisciplinarity in terms of all the metrics proposed here.

\item We develop an unsupervised classification algorithm using these metrics to identify the core and the interdisciplinary fields.

\item Core-periphery analysis on the citation network shows that the interdisciplinary fields are accelerating steadily toward the core of
computer science domain. 

\item For already very interdisciplinary fields, such as Data Mining, the indicators may have a certain ``saturation'' effect forcing it
towards the core region of the computer science domain.


\end{enumerate}


%\if{0}
\section{Challenges}
With this new trend and new avenue a set of challenges also becomes prominent. In this section, we discuss important challenges of Wi-Fi network.\\

\begin{enumerate}[(a)]
\item The average behavior indicates that a researcher tends to adopt few research fields in her entire research career, and she seems to
prefer to work simultaneously on all of them together.

\item A highly-cited researcher tends to work in many fields over her entire career but remains confined to one or few fields in
each time window. However, the number of such researchers is very less in our dataset.  

\item The researchers who have tried various fields in the entire career as well and in each successive time period, get low citations.


\end{enumerate}


\subsection{Community-based Applications}
Once the community structure of a network is detected, a natural question would be as to how can we use this information in designing real
systems. We use publication dataset, citation network and the community structure, and design two applications -- future citation
count prediction of a paper after publication and faceted recommendation system for scientific articles. The major contributions from this
study are mentioned below.

\begin{enumerate}
 \item We first start analyzing the citation profile of the papers and reveal six different patterns -- a profile with an initial peak
(PeakInit), with distinct multiple peaks (PeakMul), that exhibits a peak late in time (PeakLate), that is monotonically decreasing (MonDec),
that is monotonically increasing (MonIncr) and that can not be categorized into any of the above (Oth)).

\item While analyzing the characteristic of these categories, we observe that most of the papers in PeakInit (64.35\%) and
MonDec (60.73\%) categories are published in conferences, whereas papers belonging to PeakLate (60.11\%) and MonIncr (74.74\%)
categories are
mostly published in journals. Hence, if a publication starts receiving greater attention or citations at a later part of its lifetime, it is
more likely to be published in a journal and vice versa.


\item We observe that papers in MonDec are vastly affected by the self-citation phenomenon, i.e., around 35\% of papers in MonDec would have
been in the `Oth' category had it not been due to the self-citations. The result also agrees with the observation that  MonIncr
category is least affected by self-citations, followed by PeakLate, PeakMul and PeakInit in that order.

\item We study the stability of each category by analyzing the migration of papers from one category to others over time. We
observe that apart from the Oth category, MonDec seems to be the most stable, which is followed by PeakInit. However, papers which 
are assumed to fall in Oth category quite often turn out to be MonIncr papers in the later time periods. 

\item We analyze the core-periphery organization of the citation network and observe that PeakMul category gradually leaves the peripheral
region over time and mostly occupies the innermost shells. PeakInit and MonDec show almost similar behavior with a major proportion of
papers in inner cores in the initial year but gradually shifting towards peripheral regions. On the other hand, MonIncr and PeakLate show
expected behavior with their proportion increasing in the inner shells over time indicating their rising relevance as time progresses.

\item Our proposed framework for future citation count prediction incorporates a stratified learning approach in the traditional framework
which in turn remarkably enhances the overall performance of the prediction model.

\item Our two-stage model produces significantly better accuracy in predicting the future citation count of the highly-cited
papers that might serve as an useful tool in early prediction of the seminal papers that are going to be popular in the near future.

\item The faceted recommendation system, FeRoSA is primarily built on the semantic annotation of citations in citation network. While
evaluating the system based on expert judgment, FeRoSA achieves an overall precision (OP) of 0.65, 29.5\% higher than the
next best
system. Thus, the recommendations generated by our framework are found to be of high quality even if the method is very simple to
implement. 

\item FeRoSA also achieves a reasonably high precision for the query papers with low citations (OP of 0.57 with the next
best system having an OP of 0.46).

\item We observe once again that although FeRoSA is designed for faceted recommendation, it significantly outperforms the baselines due to
an inherent stratification (dividing the general graph into facet-wise subgraphs) which leads to a better ranking. 

\end{enumerate}


\section{Organization of the Thesis}
The thesis is organized into seven chapters.

{\bf Chapter 2} presents a detailed literature survey on the state-of-the-art in community analysis for different networks
and their usage in different applications. 

{\bf Chapter 3} centers around our first objective of constant communities in complex networks. We detect constant communities in a
brute-force manner and study their structural properties. We show that identifying constant communities prior to any community detection
enhances the performance of any community detection algorithms.

{\bf Chapter 4} investigates in detail our second objective, i.e., formulation of permanence and overlapping permanence for community
analysis. We further develop two community detection algorithms using these metrics.

{\bf Chapter 5} explains our third objective of analyzing the ground-truth community structure of citation network. We study three
subproblems pertaining  to citation network. First, we unfold the rise and fall of scientific research in computer science domain over last
fifty years. Second, we propose four metrics to quantify the degree of interdisciplinarity of a research field. Third, we study the field
adoption process of a researcher over her entire research career.

{\bf Chapter 6} presents our final objective of designing different community-based applications. In particular, we design two
systems: (i) future citation count prediction of a scientific article after publication, and (ii) a faceted paper recommendation system for
scientific articles.

{\bf Chapter 7} concludes the thesis by summarizing the contributions and pointing to a few topics of future research that have opened up from this work.

 

